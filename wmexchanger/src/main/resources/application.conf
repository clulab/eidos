rest {
    consumer {
        service: "https://localhost/dart/api/v1/cdrs"
        service: ${?REST_CONSUMER_SERVICE}
        annotations: false
        username: eidos
        username: ${?REST_CONSUMER_USERNAME}
        password: eidos_pass
        password: ${?REST_CONSUMER_PASSWORD}

        interactive: true
        duration {
            wait: 20000
            pause: 5000
        }
    }
    producer {
        service: "https://localhost/dart/api/v1/readers/upload"
        service: ${?REST_PRODUCER_SERVICE}
        username: eidos
        username: ${?REST_PRODUCER_USERNAME}
        password: eidos_pass
        password: ${?REST_PRODUCER_PASSWORD}

        interactive: true
        duration {
          wait: 20000
          pause: 5000
        }
    }
}

curl {
    producer {
            service: "https://localhost/dart/api/v1/wm-readers/reader/upload"
            service: ${?CURL_PRODUCER_SERVICE}
            username: eidos
            username: ${?CURL_PRODUCER_USERNAME}
            password: eidos_pass
            password: ${?CURL_PRODUCER_PASSWORD}
        }
}

eidos {
  interactive: true
  duration {
    wait: 20000
    pause: 5000
  }
}

kafka {
    app {
        # Put these two values into the command line.
        topic: ${?KAFKA_APP_TOPIC}
        output.dir: ${?KAFKA_APP_OUTPUT_DIR}
        # Poll for 10 seconds each time.
        poll.duration: 10
        poll.duration: ${?KAFKA_APP_POLL_DURATION}
        # This one is measured in milliseconds.
        wait.duration: 20000
        wait.duration: ${?KAFKA_APP_WAIT_DURATION}
        # This one is measured in seconds.
        close.duration: 10
        close.duration: ${?KAFKA_APP_CLOSE_DURATION}
        interactive: true
        interactive: ${?KAFKA_APP_INTERACTIVE}
    }
    consumer {
        application.id: eidos
        group.id: eidos
        poll.timeout.millis: 2000
        key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        bootstrap.servers: "localhost:9093"
        bootstrap.servers: ${?KAFKA_CONSUMER_BOOTSTRAP_SERVERS}

        # These properties will ensure that your consumer always starts from the beginning and drains the topic.
        auto.offset.reset: earliest
        auto.offset.reset: ${?KAFKA_CONSUMER_AUTO_OFFSET_RESET}
        enable.auto.commit: false
        enable.auto.commit: ${?KAFKA_CONSUMER_ENABLE_AUTO_COMMIT}

        sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"eidos\" password=\"eidos-pass\";"
        sasl.jaas.config: ${?KAFKA_CONSUMER_APP_SASL_JAAS_CONFIG}
        sasl.mechanism: PLAIN
        security.protocol: SASL_PLAINTEXT
        security.protocol: ${?KAFKA_CONSUMER_SECURITY_PROTOCOL}
    }
}
