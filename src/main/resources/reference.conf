EidosSystem {
  // These are the default values, since they are in reference.conf.
  language = english
  finders = ["gazetteer", "rulebased", "causal"]
  keepStatefulConcepts = false
  // Dirs are expected to be files, and usually begin with .
  cacheDir = ./cache
  domain = wm
  // Paths are expected to be resources, and usually begin with /
  path = /org/clulab/${EidosSystem.domain}/eidos/${EidosSystem.language}

  taxonomyPath = ${EidosSystem.path}/grammars/taxonomy.yml

  hedgingPath = ${EidosSystem.path}/confidence/hedging.txt

  useLexicons = true

  conceptExpander = { include required("englishConceptExpander.conf") }
}

filtering {
  path = ${EidosSystem.path}/filtering

    stopWordsPath = ${filtering.path}/stops.txt
  transparentPath = ${filtering.path}/transparent.txt
}

actions {
  taxonomyPath = ${EidosSystem.taxonomyPath}
  useExpansion = true
  expander = { include required("englishActionsExpander.conf") }
}

ontologies {
  // W2V
  useGrounding = false
  wordToVecPath = ${EidosSystem.path}/w2v/vectors
  //wordToVecPath = ${EidosSystem.path}/w2v/glove.840B.300d
  topKNodeGroundings = 10 // FIXME: we should not be maintaining the these in multiple places
  // Caching, for quick loading, language dependent
  cacheDir = ${EidosSystem.cacheDir}/${EidosSystem.language}
  useCacheForOntologies = false
  useCacheForW2V = ${ontologies.useCacheForOntologies}
  includeParents = true
  groundTopN = 3
  groundThreshold = 0.2
  groundNegScoreThreshold = 0.5
  groundPenalizeValue = 0.2
  // Activated Ontologies
  ontologies = ["un", "wdi", "fao", "props", "mitre12", "who"] // , "interventions", "icasa", "mesh"]
  path = ${EidosSystem.path}/ontologies

  // Primary
    // Note that these first two are included via the build.sbt libraryDependencies on WorldModelers % Ontologies.
    wm               = ${ontologies.path}/wm_metadata.yml
    wm_flattened     = ${ontologies.path}/wm_with_flattened_interventions_metadata.yml
    wm_compositional = ${ontologies.path}/CompositionalOntology_metadata.yml
    interventions    = ${ontologies.path}/interventions_metadata.yml
    // Legacy
    un               = ${ontologies.path}/un_ontology.yml
    props            = ${ontologies.path}/un_properties.yml
    // Plugins
    interventions    = ${ontologies.path}/interventions_metadata.yml
    // Indicators
    mitre12          = ${ontologies.path}/mitre12_indicators.yml
    who              = ${ontologies.path}/who_ontology.yml
    MaaS-model       = ${ontologies.path}/MaaS-model-ontology-edited.yaml
    MaaS-parameter   = ${ontologies.path}/MaaS-parameter-ontology.yaml
    MaaS-variable    = ${ontologies.path}/MaaS-variable-ontology.yaml
    // Variables
    icasa            = ${ontologies.path}/icasa.yml
    // Other
    mesh             = ${ontologies.path}/mesh_ontology.yml
}

ruleBasedEntityFinder {
  path = ${EidosSystem.path}/grammars

  entityRulesPath = ${ruleBasedEntityFinder.path}/entities/grammar/entities.yml
   avoidRulesPath = ${ruleBasedEntityFinder.path}/avoidLocal.yml
}

geonorm {
  geoNamesDir = ${EidosSystem.cacheDir}/geonames
}

timenorm {
  timeRegexPath = ${EidosSystem.path}/context/timenorm-regexes.txt
}

seasons {
  seasonsDBPath = ${EidosSystem.path}/context/seasons-db.yml
}

gazetteers {
  // This may not begin with a leading /.
  path = org/clulab/${EidosSystem.domain}/eidos/${EidosSystem.language}/lexicons
  lexicons = [
    ${gazetteers.path}/Quantifier.tsv,
    ${gazetteers.path}/Property.tsv,
    ${gazetteers.path}/Location.tsv
  ]
}

causal {
  rulesPath = ${EidosSystem.path}/grammars/master.yml
  actions = ${actions}
  useGlobalAction = true
}

adjectiveGrounder {
  useAdjectives = true
  path = ${EidosSystem.path}/quantifierKB

  domainParamKBPath = ${adjectiveGrounder.path}/domain_parameters.kb
   quantifierKBPath = ${adjectiveGrounder.path}/gradable_adj_fullmodel.kb
}

resourcer {
  useFile = false
}

coref {
    useCoref = true
    corefType = "causalBasic"
    taxonomyPath = ${EidosSystem.taxonomyPath}
}

sentenceClassifier {
  enable = true
  classifierPath = ${EidosSystem.path}/sentenceClassifier
  tokenIDFWeights = ${sentenceClassifier.classifierPath}/sentence_classifier_idf_weight_1000_20000.txt
  evaluationFilePath = ${sentenceClassifier.classifierPath}/SentenceClassifierEvaluation.tsv
  classificationThreshold = 0.7
}
